{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bc138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd957a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df =pd.read_csv(r'F:\\Kabir\\CSUN\\R\\preprocessed_reddit_comments_python_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b2c86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSTNAME</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>rejoined_tokenized_comments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Immaculate' Review Thread : r/boxoffice</td>\n",
       "      <td>Daydream_machine</td>\n",
       "      <td>Oof that’s admittedly lower than I expected. D...</td>\n",
       "      <td>oof admittedly lower expected disappointed rea...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['oof', 'admittedly', 'lower', 'expected', 'di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Immaculate' Review Thread : r/boxoffice</td>\n",
       "      <td>Interesting_Tie_1870</td>\n",
       "      <td>There is a scene towards the beginning of the ...</td>\n",
       "      <td>scene towards beginning movie feature red flas...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['scene', 'towards', 'beginning', 'movie', 'fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   POSTNAME                AUTHOR  \\\n",
       "0  'Immaculate' Review Thread : r/boxoffice      Daydream_machine   \n",
       "1  'Immaculate' Review Thread : r/boxoffice  Interesting_Tie_1870   \n",
       "\n",
       "                                             COMMENT  \\\n",
       "0  Oof that’s admittedly lower than I expected. D...   \n",
       "1  There is a scene towards the beginning of the ...   \n",
       "\n",
       "                         rejoined_tokenized_comments sentiment  \\\n",
       "0  oof admittedly lower expected disappointed rea...  negative   \n",
       "1  scene towards beginning movie feature red flas...  positive   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  ['oof', 'admittedly', 'lower', 'expected', 'di...  \n",
       "1  ['scene', 'towards', 'beginning', 'movie', 'fe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629090be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_counter(text):\n",
    "    return round((sum([1 for i in text if i in string.punctuation])*100/(len(text) - text.count(\" \"))),2)\n",
    "\n",
    "df['punctuation_percent'] = df['COMMENT'].apply(punctuation_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226af816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming to avoid sentiment class deletion during training.\n",
    "df = df.rename(columns={'sentiment': 'sentiment_class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6047bb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSTNAME</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>rejoined_tokenized_comments</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>punctuation_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Immaculate' Review Thread : r/boxoffice</td>\n",
       "      <td>Daydream_machine</td>\n",
       "      <td>Oof that’s admittedly lower than I expected. D...</td>\n",
       "      <td>oof admittedly lower expected disappointed rea...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['oof', 'admittedly', 'lower', 'expected', 'di...</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Immaculate' Review Thread : r/boxoffice</td>\n",
       "      <td>Interesting_Tie_1870</td>\n",
       "      <td>There is a scene towards the beginning of the ...</td>\n",
       "      <td>scene towards beginning movie feature red flas...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['scene', 'towards', 'beginning', 'movie', 'fe...</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   POSTNAME                AUTHOR  \\\n",
       "0  'Immaculate' Review Thread : r/boxoffice      Daydream_machine   \n",
       "1  'Immaculate' Review Thread : r/boxoffice  Interesting_Tie_1870   \n",
       "\n",
       "                                             COMMENT  \\\n",
       "0  Oof that’s admittedly lower than I expected. D...   \n",
       "1  There is a scene towards the beginning of the ...   \n",
       "\n",
       "                         rejoined_tokenized_comments sentiment_class  \\\n",
       "0  oof admittedly lower expected disappointed rea...        negative   \n",
       "1  scene towards beginning movie feature red flas...        positive   \n",
       "\n",
       "                                          lemmatized  punctuation_percent  \n",
       "0  ['oof', 'admittedly', 'lower', 'expected', 'di...                 3.38  \n",
       "1  ['scene', 'towards', 'beginning', 'movie', 'fe...                 0.68  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de05b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['rejoined_tokenized_comments',\n",
    "                                                        'punctuation_percent']],\n",
    "                                                    df['sentiment_class'], test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6512c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ee428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'rejoined_tokenized_comments' column to Unicode strings\n",
    "X_train['rejoined_tokenized_comments'] = X_train['rejoined_tokenized_comments'].values.astype('U')\n",
    "X_test['rejoined_tokenized_comments'] = X_test['rejoined_tokenized_comments'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "917f486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit TF-IDF vectorizer on training text data\n",
    "X_train_tfidf_text = tfidf_vectorizer.fit_transform(X_train['rejoined_tokenized_comments'])\n",
    "\n",
    "# Get feature names (words) representing the column names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd830c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform both training and test text data\n",
    "X_train_tfidf_text = tfidf_vectorizer.transform(X_train['rejoined_tokenized_comments'])\n",
    "X_test_tfidf_text = tfidf_vectorizer.transform(X_test['rejoined_tokenized_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901d09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TF-IDF transformed text features to DataFrame with meaningful column names\n",
    "X_train_final = pd.DataFrame(X_train_tfidf_text.toarray(), columns=feature_names)\n",
    "X_test_final = pd.DataFrame(X_test_tfidf_text.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701c9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate TF-IDF transformed text features with original numeric features\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train['punctuation_percent'].reset_index(drop=True, inplace=True)\n",
    "X_train_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "X_test['punctuation_percent'].reset_index(drop=True, inplace=True)\n",
    "X_test_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train_final3 = pd.concat([y_train, X_train_final, \n",
    "                           X_train['punctuation_percent']], axis=1)\n",
    "X_test_final3 = pd.concat([y_test, X_test_final, \n",
    "                          X_test['punctuation_percent']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5107a447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>aake</th>\n",
       "      <th>aapki</th>\n",
       "      <th>aapse</th>\n",
       "      <th>abhorrent</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>able</th>\n",
       "      <th>abomination</th>\n",
       "      <th>abrasive</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomedin</th>\n",
       "      <th>zoomers</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zz</th>\n",
       "      <th>zürich</th>\n",
       "      <th>äckligt</th>\n",
       "      <th>åt</th>\n",
       "      <th>punctuation_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment_class  aake  aapki  aapse  abhorrent  ability  abject  able  \\\n",
       "2712        negative   0.0    0.0    0.0        0.0      0.0     0.0   0.0   \n",
       "2713        positive   0.0    0.0    0.0        0.0      0.0     0.0   0.0   \n",
       "2714        positive   0.0    0.0    0.0        0.0      0.0     0.0   0.0   \n",
       "2715        positive   0.0    0.0    0.0        0.0      0.0     0.0   0.0   \n",
       "2716        negative   0.0    0.0    0.0        0.0      0.0     0.0   0.0   \n",
       "\n",
       "      abomination  abrasive  ...  zoo  zoom  zoomedin  zoomers  zooming   zz  \\\n",
       "2712          0.0       0.0  ...  0.0   0.0       0.0      0.0      0.0  0.0   \n",
       "2713          0.0       0.0  ...  0.0   0.0       0.0      0.0      0.0  0.0   \n",
       "2714          0.0       0.0  ...  0.0   0.0       0.0      0.0      0.0  0.0   \n",
       "2715          0.0       0.0  ...  0.0   0.0       0.0      0.0      0.0  0.0   \n",
       "2716          0.0       0.0  ...  0.0   0.0       0.0      0.0      0.0  0.0   \n",
       "\n",
       "      zürich  äckligt   åt  punctuation_percent  \n",
       "2712     0.0      0.0  0.0                 3.23  \n",
       "2713     0.0      0.0  0.0                 3.08  \n",
       "2714     0.0      0.0  0.0                 1.65  \n",
       "2715     0.0      0.0  0.0                 2.44  \n",
       "2716     0.0      0.0  0.0                 3.12  \n",
       "\n",
       "[5 rows x 6245 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68cdd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final3.to_csv(r'F:\\Kabir\\CSUN\\R\\training_data_final.csv', index=False)\n",
    "X_test_final3.to_csv(r'F:\\Kabir\\CSUN\\R\\testing_data_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26b6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r'F:\\Kabir\\CSUN\\R\\tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfidf_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accbcaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
